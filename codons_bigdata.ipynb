{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following script was written as a part of an open-ended independent research project conducted for CS 431: Data Intensive Distributed Analytics (big data).\n",
        "\n",
        "I’m Sunny, and welcome to my solo project! I will be exploring simple methods of comparing genome sequences. In the end, I will be discussing some of the ways we can extrapolate my simple experiments in the field, limitations of my case study, and how to interpret my findings in the context of today’s knowledge. I apply some basic big data methods and assess their effectiveness in being able to compare genome sequences. I learned a lot from jumping into this project, and I hope you enjoy it as much as I did. :)\n",
        "\n",
        "During my search for interesting datasets, I noticed a lot of “COVID-19 genome sequencing” datasets. After inquiring, I got this insight: there is more info about genes in databases than researchers have been able to run experiments on! Furthermore, finding patterns in DNA today depends on the validity of conclusions drawn from a limited number of experiments that were previously done, and so the propagation of error is a big issue here.\n",
        "\n",
        "The main purpose of my project is to explore what data we can extract from having two samples and no database with previous knowledge to pull from. How can my current knowledge allow me to extrapolate data?\n",
        "\n",
        "To begin, I wanted a way to just “eyeball” the data. It was a bit difficult to look at blocks of letters, so I thought of a really simple hash, where for each block, I count the number of occurrences of each letter, and store them as a set, and that’s the hash.\n",
        "\n",
        "Obviously, this hash is not useful for comparing the actual sequences themselves, but taking a brief look at the resultant hashes for two genomes of coronavirus type 2, I quickly noticed that they looked pretty similar. Each line seemed to differ by approximately 1 character, and one character only. It was then that I actually looked at the data, and noticed that all my samples for this kind of viral species type were almost identical, and only differed in the first few characters (in spaces that might be referred to as junk DNA), and in the last characters, in the place that is often referred to as the poly-A tail.\n",
        "\n",
        "This makes a lot of sense because, we do expect to see some variation in all of our samples,\n",
        "Genome sequencing is often imperfect, and may have errors or gaps in the data, making it advantageous to have multiple samples, which improves the “resolution” of the data.\n",
        "Based on contextual knowledge, we know that the various samples are genetically very similar, as there has been limited time for the virus to spread and mutate.\n",
        "\n",
        "So, rather than comparing two sequences from the same strain, I decided to compare “coronavirus” and a “coronavirus 2” dataset. These are the names of different kinds of coronaviruses.\n",
        "\n",
        "The data that I had was divided into lines of 70 characters, and each sample had about 400 lines. Obviously a hash is pretty sensitive, and would be thrown off even in nearly identical samples. For me, this meant that I wanted to try to figure out a better way to divide the data to analyse, rather than arbitrary lines of length 70.\n",
        "\n",
        "Comparing DNA sequences is not quite the same as comparing files, for example, to read DNA, we are looking for “open reading frame,” the beginning of which are marked with these things called start codons, which are pretty much always “AGT.”\n",
        "But i thought i’d try some techniques that we learned about file comparison anyway.\n",
        "One method that did occur to me, was to create a dictionary of multiple permutations of letters. However, even with lines of 70 characters, we would develop a huge workload really fast. While this is completely doable in spark, I was more interested in exploring shortcuts. Given more time, perhaps I would have implemented this model in order to compare to the other models.\n",
        "\n",
        "The model that I DID trY was to flatMap and split the data by start codons. So, at every occurrence of “AGT,” split the data.\n",
        "\n",
        "For my two samples, from Kaggle, these are some numbers I pulled: As you can see, viruses which are more closely related had more similar results.\n",
        "one sample had 777 start codons 2143 stop codons. The second had 777 start codons and 2159 stop codons. The first had 428 lines of bases, the second had 427.\n",
        "\n",
        "For comparison, I also calculated these metrics on a different strain. The previous were coronavirus 2. For a “coronavirus” strain, there was 802 start, 2038 stop, and 426 lines. This makes sense, as we’d expect to see more deviation as the species diverges.\n",
        "\n",
        "So right away, we see the complexities of comparing gene sequences emerging. If there are mismatches between just two datasets, then we would certainly expect to see many more in larger datasets.\n",
        "\n",
        "Then I did my hashing technique again, then I reduced to see how many there were, then Ij joined with the other dataset, and only kept the pairs which had the same count. Obviously, the last filter was very unnecessary. However, I was still left with 92 pairs which were hashed the same.\n",
        "If I filtered so that the only requirement was that both sequences have the same hash, I ended with 175 unique hashes in both datasets.\n",
        "\n",
        "Given time, I would have used this information as a starting point to look for parallels. There would definitely have been challenges in figuring out ways to index in spark. But in the meantime, I think this information could be useful as a metric of how possible it is to have similarities.\n",
        "To assess validity, the number of items in the rdd which was split by start codons was 1129. Not having a lot of biology experience, this ratio seems pretty okay to me. I imagine if I were to further explore the validity of this method, I would be able to develop an ideal ratio to estimate the similarity of the two sets.\n",
        "\n",
        "The problem of having too much data and not enough researchers to analyse it, especially digital data, is a huge untapped market in the digital age. Using simple case studies, one could eventually over time build libraries for researchers to use which could eventually handle very complicated genome analysis.\n",
        "\n",
        "So there you have it, a summary of my brief explorations in playing with genome sequencing. There are a lot of ways to approach genome analysis, and this was more about getting a feel for the challenges than researching the methods, but I still had a lot of fun, and I hope you enjoyed. Thanks for watching, and thanks for a great term.\n"
      ],
      "metadata": {
        "id": "Gc5_5wUxV8bq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhOjADbKoDVM"
      },
      "source": [
        "# INSTALL SPARK\n",
        "\n",
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4SpJZno89g"
      },
      "source": [
        "# SET UP SPARK CONTEXT; PYSPARK\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(appName=\"YourTest\", master=\"local[*]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azokwt0Y8Buk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUYdPbGep2Ox"
      },
      "source": [
        "Journal notes:\n",
        "This is a personal project, playing with genome datasets using big data methods.\n",
        "\n",
        "I will start by preparing two datasets, of two separately sequenced complete COVID genomes, and compare them.\n",
        "\n",
        "Prep the files, compare the length. Everything i learn about these sets will be new to me, and I'll explore the meaning of what I'm studying.\n",
        "\n",
        "My hash can be a LIST of four numbers, each number counting the number of A,C,G,T?\n",
        "\n",
        "Currently, my objective for this project is to explore various combinations of samples we can create out of two genome samples in order to compare the two. This will involve creating functions to identify start and stop codons, which have many combinations, as well as matching up start codons with potential stop codons, and then comparing the lists of genomes developed for both sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M-ux9P_upX4"
      },
      "source": [
        "PREPARING GENOME SEQUENCE A (genome2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhO1Y-cmudZW",
        "outputId": "d852101b-c33f-4d00-e6a2-b908d6e3f176"
      },
      "source": [
        "!wget -q /content/drive/MyDrive/1 - Term 4A/CS 431/genome1.rtf\n",
        "\n",
        "# hash data, one set (count_A, c_C, c_G, c_T) per line\n",
        "\n",
        "# line is an RDD, form such as ['A', 'T', 'G', 'G']\n",
        "def parsing(line):\n",
        "  new = []\n",
        "  for letter in line:\n",
        "    new = new + [(letter, 1)]\n",
        "  return new\n",
        "\n",
        "# fake reduce by key, takes in list of kv pairs\n",
        "def rbk(kv):\n",
        "  a = 0\n",
        "  c = 0\n",
        "  g = 0\n",
        "  t = 0\n",
        "  for pair in kv:\n",
        "    if pair[0] == 'A':\n",
        "      a = a + 1\n",
        "    elif pair[0] == 'C':\n",
        "      c = c + 1\n",
        "    elif pair[0] == 'G':\n",
        "      g = g + 1\n",
        "    elif pair[0] == 'T':\n",
        "      t = t + 1\n",
        "    else:\n",
        "      print('problem!!')\n",
        "  return (a, c, g, t)\n",
        "\n",
        "lines2 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/genome2.txt')\n",
        "\n",
        "# LISTLINE\n",
        "# makes an RDD of lists, ['A', 'T', 'G', 'G'], etc\n",
        "# turns it into list of kv pairs, [('A',1), ('T',1), ('G',1), ('G',1)]\n",
        "# end result is a list of hashes, [(22, 17, 8, 23),\n",
        "#                                  (19, 16, 14, 21),\n",
        "#                                  (13, 17, 17, 23),\n",
        "#                                  (16, 16, 21, 17),\n",
        "#                                  (16, 20, 15, 19),\n",
        "#                                  (16, 13, 23, 18),\n",
        "#                                  (20, 14, 15, 21),\n",
        "#                                  (16, 16, 20, 18),\n",
        "#                                  (13, 16, 21, 20),\n",
        "#                                  (20, 13, 18, 19)]\n",
        "listline2 = lines2.map(lambda x: list(x)).map(parsing).map(rbk)\n",
        "\n",
        "listline2.take(10)\n",
        "\n",
        "#print(listline2.count())\n",
        "#lines2.take(2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(22, 17, 8, 23),\n",
              " (19, 16, 14, 21),\n",
              " (13, 17, 17, 23),\n",
              " (16, 16, 21, 17),\n",
              " (16, 20, 15, 19),\n",
              " (16, 13, 23, 18),\n",
              " (20, 14, 15, 21),\n",
              " (16, 16, 20, 18),\n",
              " (13, 16, 21, 20),\n",
              " (20, 13, 18, 19)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csnm2tYn1emd"
      },
      "source": [
        "PREPARING GENOME SEQUENCE B (genome3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeczYpjFqTO0",
        "outputId": "d1ae8abb-fb0c-407f-ef8a-6e5c7da289ff"
      },
      "source": [
        "lines3 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/ggenome3.txt')\n",
        "\n",
        "listline3 = lines3.map(lambda x: list(x)).map(parsing).map(rbk)\n",
        "\n",
        "print(listline3.count())\n",
        "listline3.take(10)\n",
        "\n",
        "# Severe acute respiratory syndrome-related coronavirus isolate Tor2, complete genome\n",
        "\n",
        "\n",
        "# every 3, NOT every one, starting at a start codon.\n",
        "# read in sets of 3, but different sets can still produce the same amino acid. so genome diff != practical diff\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(21, 18, 10, 21),\n",
              " (22, 16, 13, 19),\n",
              " (13, 18, 15, 24),\n",
              " (16, 15, 21, 18),\n",
              " (17, 17, 18, 18),\n",
              " (16, 16, 23, 15),\n",
              " (19, 16, 17, 18),\n",
              " (18, 18, 20, 14),\n",
              " (18, 18, 17, 17),\n",
              " (20, 12, 19, 19)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmsG1vCz_7Kg",
        "outputId": "177bf1d5-dd44-4076-d012-4e1d5a8cb31f"
      },
      "source": [
        "lines4 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/genome4.txt')\n",
        "\n",
        "listline4 = lines4.map(lambda x: list(x)).map(parsing).map(rbk)\n",
        "\n",
        "print(listline4.count())\n",
        "listline4.take(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(21, 18, 8, 23),\n",
              " (19, 15, 14, 22),\n",
              " (13, 17, 17, 23),\n",
              " (16, 17, 21, 16),\n",
              " (16, 19, 16, 19),\n",
              " (16, 14, 22, 18),\n",
              " (20, 13, 16, 21),\n",
              " (16, 16, 20, 18),\n",
              " (13, 16, 20, 21),\n",
              " (20, 13, 19, 18)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "klj0mUMzV7UU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnybljEP2yrb"
      },
      "source": [
        "Okay, so I'm realizing that my hash method is not the right idea, partially bcause even though comparing each individual number in this matrix, the matrix which is the DIFFERENCE between the two is not that much, there are some problems:\n",
        "- ACGT is not a huge variety of options, so the spread varies really easily\n",
        "- if you replace ONE letter difference in each row, then TWO letter counts are affected, making the results skewed really fast.\n",
        "\n",
        "But in any case, I'd love to calculate a matrix, one subtracting the other, to see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd0kK9as3Vnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32b2d15-8e38-4e82-e73f-1b03b067999c"
      },
      "source": [
        "# matrix A: listline2\n",
        "# matrix B: listline3\n",
        "\n",
        "#matrixA = listline2.collect()\n",
        "#matrixA.take(10)\n",
        "\n",
        "listline2.take(10)\n",
        "listline3.take(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(21, 18, 10, 21),\n",
              " (22, 16, 13, 19),\n",
              " (13, 18, 15, 24),\n",
              " (16, 15, 21, 18),\n",
              " (17, 17, 18, 18),\n",
              " (16, 16, 23, 15),\n",
              " (19, 16, 17, 18),\n",
              " (18, 18, 20, 14),\n",
              " (18, 18, 17, 17),\n",
              " (20, 12, 19, 19)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq9nOJl38vl5"
      },
      "source": [
        "current thoughts:\n",
        "\n",
        "brute force the calculation by comparing EACH INDIVIDUAL position in the two genomes, and then sum the similarities,  divide by total number of letters.\n",
        "\n",
        "maybe use this as my base to compare against\n",
        "\n",
        "then i have my sketchy hash method\n",
        "\n",
        "then look up some algorithms to try\n",
        "\n",
        "then at the end, extend to explain how this could be applicable if we have an enormous dataset.\n",
        "\n",
        "QUESTION: are there currently tools out there which handle MULTIPLE huge sets? Bc if not, this is great.\n",
        "\n",
        "QUESTION: why are the genome lengths different?\n",
        "\n",
        "QUESTION: how important is position? is it reasonable to compare index (i1,i2)? Order matters, but does it matter from the start? DO THEY HAVE TO BE THE SAME SIZE\n",
        "\n",
        "QUESTION: are there actual advantages to being able to compare huge masses of genomes? or is there more value in quantifying the individual differences? I'm sure by processing huge amounts, we'd be able to generate metrics about the mass of data, against which we can compare differences in extreme cases.\n",
        "\n",
        "Some research: there are ways of comparing multiple genomes at once. the purpose is either really to show the genetic relationship between two strains, or possibly to isolate mutations.\n",
        "\n",
        "https://academic.oup.com/bfg/article/10/6/322/233867 :\n",
        "Compared with ‘traditional’ genome studies that focus on a single genome per study, comparative genomics provides an additional layer of detail. A single genome can reveal the functional potential encoded within an organism with ‘tried-and-true’ annotation strategies using BLASTX, or HMM searches of protein families (e.g. COG, Pfam, TIGRfam, etc.) in order to glean functional potential of a given organism. Comparisons between different pathogen genomes, however, often lead to faster identification of distinct mechanisms underlying pathogenicity. Many types of differences have been observed between pathogens and non- or less-pathogenic relatives, from very large genomic differences as in the genomic islands found among pathogenic or benign strains within a single species (Escherichia coli) [12, 13], to smaller genomic differences between closely related species of the same genus (e.g. between Yersinia pestis and Yersinia pseudotuberculosis) [14]. While the set of genome sequence differences alone may not provide any conclusive answer as to which sequence(s) may be responsible for a specific phenotype, nevertheless, genome comparisons do generate manageable lists of genomic regions and gene candidates for further study.\n",
        "\n",
        "Obviously, there are a lot of advancements in comparative genetics that I cannot even approach for a single project like this. This changes my research question a bit, to exploring the variation in results some very simple algorithms have in comparative genetics.\n",
        "\n",
        "exploring why some algorithms work, and some don't will need more research.\n",
        "\n",
        "Here, I think for now I will just compare multiple methods on two similar genome datasets, and talk about how this would expand.\n",
        "\n",
        "For example, to actually properly test these methods, and go even deeper, we'd need far more datasets.\n",
        "\n",
        "Additionally, I think it would be cool to apply statistics. Maybe if we had a huge sample size of genomes, we could calculate an average matrix, and use that matrix to develop a standard deviation matrix, and we could easily identify at least areas which have outliers!\n",
        "\n",
        "To be clear, there are absolutely methods out there to compare large datasets of genomes quickly. From what I've gathered though, much of these methods are quite new, (fun fact: my highschool biology teacher, who was quite young, worked on the human genome sequencing project himself), they are still developing. I think it's nice because genomes and big data emerged in a similar era, and they kind of grow together. In terms of Kuhnian paradigms, they belong to the same paradigm, and grow together. As someone who studies interdisciplinarity, I am very excited at this parallel.\n",
        "\n",
        "Also from the link: \"Due to technological advances in the past few decades, sequencing whole genomes is becoming cheaper at an exponential rate. As a result, an increasing collection of whole sequenced genomes is becoming publicly available, ranging in size from less than two hundred thousand base pairs2 to more than 22 * 109 base pairs3... \n",
        "However, to improve our understanding of these topics, new data are being included in databases, but doing so comes at a price: the more genomes and larger genomes trend is aggravating a scenario where it is unthinkable to perform genomic experiments without the aid of extensive computational resources, but furthermore, even current computational methods are being left behind with the increasing complexity.\"\n",
        "\n",
        "\"Currently, most of the handling, exploration and curation of genomic information (such as identifying coding regions or generating pairwise synteny maps) is performed manually and curated with platforms dedicated to this purpose, which often include a repository of precomputed genome comparisons. For instance, NARCISSE4, Genomicus5 and SynFind6 provide such data along with other tools for exploration purposes such as genome browsers and karyotype analysers7. Although these resources contain high-quality curated information, they usually rely on previously computed data and typically do not allow users to run new experiments on demand. As a result, when new experiments are supported by these platforms, it is common to employ restricted comparison methodologies such as gene-based approaches (see CoGe8) to lower computational demands. However, these approaches are often based on the BLAST9 algorithm, which was not initially designed for large pairwise genome comparisons.\"\n",
        "\n",
        "A lot like files, I could hope in the very least that these methods could be a fast way to isolate which pairs are good CANDIDATES for further examination or comparison.\n",
        "\n",
        "The software out there that I looked into right now, there aren't any websites which do that specifically.\n",
        "\n",
        "Yes! The fact that there's more info in the databases than humans have been able to run experiments on! So finding patterns in the DNA depends on the validity of the conclusions we've drawn from a limited number of experiments that we HAVE done, so the propagation of error is a huge issue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFm2mNUoVmvI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNK22lM7UUzA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBlYYkZRUTxd"
      },
      "source": [
        "# step 1, find start codon ATG? always. find first instance, then process stuff after.\n",
        "# find stop codons also. stop codon: TAG, TAA, TGA. (could quickly google).\n",
        "# would expect to see these multiple times.\n",
        "# for every sequence, lots of genes\n",
        "# open reading frame: from start to stop. these are the actual genes. there will be lots orfs. millions/w/e\n",
        "\n",
        "# the poly A tail, AAAAAAAAAAA, like a bumper to protect end of gene. depends on sequence type.\n",
        "\n",
        "# the stuff before the start codon? read gene, make mrna to make a protein. junk dna wasn't relevant before, but it actually controls the amount\n",
        "# of the protein, regulation, etc. it's not useless. not translated to protein, but used in expression.\n",
        "\n",
        "# human genome project: 22,000-25,000 genes!\n",
        "# COVID is a viral thing, so it's tinier\n",
        "# DNA tries to be efficient. relationship bw how much dna it takes to code the exterior and some other stuff.\n",
        "\n",
        "# website with annotated gene records (lots!! link)\n",
        "# links me to different ways of comparing existing datasets\n",
        "# mimick!\n",
        "# \"explore the data\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMs4gHvOVn1_",
        "outputId": "e34f8333-3f99-41d2-d0c4-8044c8be30b3"
      },
      "source": [
        "lines2 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/genome2.txt')\n",
        "\n",
        "# find start codon\n",
        "def start(line):\n",
        "  count = 0\n",
        "  A = 0\n",
        "  T = 0\n",
        "  for letter in line:\n",
        "    #print(letter)\n",
        "\n",
        "    if letter == 'A':\n",
        "      if A == 1:\n",
        "        continue\n",
        "      elif A == 0:\n",
        "        A = 1\n",
        "        #print('change?')\n",
        "        #print(A)\n",
        "\n",
        "    elif letter == 'T':\n",
        "      if A == 0:\n",
        "        continue\n",
        "      else:\n",
        "        if T == 0:\n",
        "          T = 1\n",
        "          #print('change?')\n",
        "          #print(T)\n",
        "        else:\n",
        "          A = 0\n",
        "          T = 0\n",
        "          #print('refresh')\n",
        "          #print(A)\n",
        "          #print(T)\n",
        "    \n",
        "    elif letter == 'G':\n",
        "      if A == 0:\n",
        "        continue\n",
        "      else:\n",
        "        if T == 0:\n",
        "          A = 0\n",
        "        else:\n",
        "          count = count + 1\n",
        "          A = 0\n",
        "          T = 0\n",
        "          #print('UPDATE')\n",
        "          #print(count)\n",
        "    else:\n",
        "      A = 0\n",
        "      T = 0\n",
        "\n",
        "  return count\n",
        "\n",
        "count_start = lines2.map(start)\n",
        "\n",
        "count_start2 = count_start.reduce(lambda x,y: x+y)\n",
        "\n",
        "\n",
        "count_start4 = lines4.map(start)\n",
        "\n",
        "count_start44 = count_start4.reduce(lambda x,y: x+y)\n",
        "\n",
        "\n",
        "print(count_start2)\n",
        "print(count_start44)\n",
        "print(start('ATCTATCGATGAA'))\n",
        "print(start('ATCTATCGATGAATG'))\n",
        "#start('ATG')\n",
        "\n",
        "count_start.take(10)\n",
        "#[0, 1, 0, 1, 0, 1, 1, 3, 1, 2]\n",
        "\n",
        "lines2.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "777\n",
            "777\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAA',\n",
              " 'CGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACTCACGCAGTATAATTAATAAC',\n",
              " 'TAATTACTGTCGTTGACAGGACACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTG',\n",
              " 'TTGCAGCCGATCATCAGCACATCTAGGTTTCGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTC',\n",
              " 'CCTGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGTGCTCGTAC',\n",
              " 'GTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCTTAAAGATGGCACTTGTGG',\n",
              " 'CTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACAGCCCTATGTGTTCATCAAACGTTCGGAT',\n",
              " 'GCTCGAACTGCACCTCATGGTCATGTTATGGTTGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTC',\n",
              " 'GTAGTGGTGAGACACTTGGTGTCCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCT',\n",
              " 'TCTTCGTAAGAACGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTA']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dySG3QilbJVW",
        "outputId": "f5d58e1f-f2f9-412c-a59c-983953e3d919"
      },
      "source": [
        "lines2 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/genome2.txt')\n",
        "\n",
        "\n",
        "# FIND END CODONS: TAG, TAA, TGA\n",
        "\n",
        "# find start codon\n",
        "def end(line):\n",
        "  count = ''\n",
        "  total = 0\n",
        "  for letter in line:\n",
        "    #print(letter)\n",
        "\n",
        "    if letter == 'T':\n",
        "      if count == '':\n",
        "        count = 'T'\n",
        "      elif count == 'T':\n",
        "        continue\n",
        "      else:\n",
        "        count = ''\n",
        "        #print('change?')\n",
        "        #print(count)\n",
        "\n",
        "    elif letter == 'A':\n",
        "      if count == '':\n",
        "        continue\n",
        "      elif count == 'T':\n",
        "        count = 'TA'\n",
        "        #print(count)\n",
        "      else:\n",
        "        total = total + 1\n",
        "        count = ''\n",
        "        #print('UPDATE')\n",
        "        #print(total)\n",
        "    \n",
        "    elif letter == 'G':\n",
        "      if count == '':\n",
        "        continue\n",
        "      elif count == 'T':\n",
        "        count = 'TG'\n",
        "        #print('change?')\n",
        "        #print(count)\n",
        "      elif count == 'TA':\n",
        "        count = ''\n",
        "        total = total + 1\n",
        "        #print('UPDATE')\n",
        "        #print(total)\n",
        "      else:\n",
        "        count = ''\n",
        "    else:\n",
        "      A = 0\n",
        "      T = 0\n",
        "\n",
        "  return total\n",
        "\n",
        "count_end = lines2.map(end)\n",
        "\n",
        "count_end2 = count_end.reduce(lambda x,y: x+y)\n",
        "\n",
        "\n",
        "count_end4 = lines4.map(end)\n",
        "count_end44 = count_end4.reduce(lambda x,y: x+y)\n",
        "\n",
        "print(count_end2)\n",
        "print(count_end44)\n",
        "#print(start('ATCTATCGATGAA'))\n",
        "#print(start('ATCTATCGATGAATG'))\n",
        "\n",
        "#count_start.take(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2143\n",
            "2159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012ubgISICDp"
      },
      "source": [
        "let's compare a coronavirus and a coronavirus 2. let's do it by building a keys dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPKFJ2GJIHnr",
        "outputId": "663f0bcc-45e7-4121-c47f-5b70d8fd20bc"
      },
      "source": [
        "listline2.take(30)\n",
        "\n",
        "variations = listline2.map(lambda x: (x, 1)).reduceByKey(lambda x,y: x+y).sortByKey()\n",
        "\n",
        "variations.take(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((9, 15, 14, 32), 1),\n",
              " ((11, 9, 16, 34), 1),\n",
              " ((11, 14, 18, 27), 1),\n",
              " ((11, 15, 11, 33), 1),\n",
              " ((12, 9, 12, 37), 1),\n",
              " ((12, 12, 15, 31), 1),\n",
              " ((12, 14, 8, 36), 1),\n",
              " ((12, 14, 11, 33), 1),\n",
              " ((13, 0, 0, 0), 1),\n",
              " ((13, 15, 8, 34), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV-kz4D5JCf9",
        "outputId": "973c3fe6-e752-4d48-b643-8d92aad22158"
      },
      "source": [
        "\n",
        "listline3.take(30)\n",
        "\n",
        "variations3 = listline3.map(lambda x: (x, 1)).reduceByKey(lambda x,y: x+y).sortByKey()\n",
        "\n",
        "variations3.take(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 0, 0, 0), 1),\n",
              " ((9, 14, 19, 28), 1),\n",
              " ((9, 17, 13, 31), 1),\n",
              " ((10, 11, 21, 28), 1),\n",
              " ((11, 13, 20, 26), 1),\n",
              " ((11, 15, 15, 29), 1),\n",
              " ((11, 16, 14, 29), 1),\n",
              " ((11, 18, 13, 28), 1),\n",
              " ((11, 19, 15, 25), 1),\n",
              " ((12, 10, 18, 30), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S8WIRkNJFDi"
      },
      "source": [
        "k = 30\n",
        "# only looking at sequences of at least 30\n",
        "\n",
        "# one method is looking at identical hashes, and comparing those lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZqhXbxTK4Ls",
        "outputId": "2e94e4be-4d23-42cb-b813-89070b7844bd"
      },
      "source": [
        "# trying from scratch, separating data by start codons\n",
        "\n",
        "lines2 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/genome2.txt')\n",
        "\n",
        "listline2 = lines2.flatMap(lambda x: x.split('ATG')).map(parsing).map(rbk).map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortByKey(False)\n",
        "\n",
        "#print(listline2.count())\n",
        "listline2.take(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((34, 15, 12, 9), 1),\n",
              " ((33, 7, 11, 19), 1),\n",
              " ((32, 17, 8, 13), 1),\n",
              " ((31, 9, 15, 15), 1),\n",
              " ((28, 15, 8, 19), 1),\n",
              " ((28, 14, 8, 20), 1),\n",
              " ((28, 13, 16, 13), 1),\n",
              " ((27, 11, 10, 22), 1),\n",
              " ((26, 12, 11, 21), 1),\n",
              " ((26, 11, 15, 18), 2),\n",
              " ((26, 9, 4, 19), 1),\n",
              " ((25, 18, 15, 12), 1),\n",
              " ((25, 14, 15, 16), 2),\n",
              " ((25, 14, 13, 15), 1),\n",
              " ((25, 12, 18, 15), 1),\n",
              " ((25, 11, 12, 22), 1),\n",
              " ((25, 11, 8, 19), 1),\n",
              " ((24, 14, 11, 21), 1),\n",
              " ((24, 13, 13, 20), 1),\n",
              " ((24, 12, 15, 19), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TDFbtvURre1",
        "outputId": "3e4efcc6-5ea7-4e25-a6ee-3a44f9aac545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "listline2 = lines2.flatMap(lambda x: x.split('ATG'))\n",
        "listline2.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnzkekJxOYcC",
        "outputId": "5becef7b-a9a3-4138-c72b-cc4f7a20c2b8"
      },
      "source": [
        "lines3 = sc.textFile('/content/drive/MyDrive/1 - Term 4A/CS 431/ggenome3.txt')\n",
        "\n",
        "listline3 = lines3.flatMap(lambda x: x.split('ATG')).map(parsing).map(rbk).map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortByKey(False)\n",
        "\n",
        "#print(listline2.count())\n",
        "listline3.take(20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((32, 15, 16, 7), 1),\n",
              " ((31, 14, 9, 7), 1),\n",
              " ((28, 19, 12, 11), 1),\n",
              " ((27, 8, 13, 22), 1),\n",
              " ((26, 18, 14, 12), 1),\n",
              " ((26, 17, 14, 13), 1),\n",
              " ((26, 16, 13, 15), 1),\n",
              " ((26, 14, 14, 16), 1),\n",
              " ((26, 9, 14, 21), 1),\n",
              " ((25, 17, 11, 17), 1),\n",
              " ((25, 16, 14, 15), 1),\n",
              " ((25, 16, 12, 14), 1),\n",
              " ((25, 15, 14, 16), 1),\n",
              " ((25, 14, 15, 16), 1),\n",
              " ((25, 12, 15, 18), 1),\n",
              " ((24, 14, 12, 20), 1),\n",
              " ((24, 13, 14, 19), 1),\n",
              " ((24, 1, 0, 0), 1),\n",
              " ((23, 18, 16, 13), 1),\n",
              " ((23, 17, 16, 14), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFbHCgHEPyr_",
        "outputId": "ce82f229-154b-4891-a35d-e54779f37214"
      },
      "source": [
        "merge = listline2.join(listline3)\n",
        "\n",
        "merge.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((25, 14, 15, 16), (2, 1)),\n",
              " ((15, 8, 6, 11), (1, 1)),\n",
              " ((9, 4, 3, 2), (1, 1)),\n",
              " ((9, 3, 3, 5), (1, 1)),\n",
              " ((8, 9, 5, 6), (1, 1)),\n",
              " ((8, 5, 5, 14), (1, 2)),\n",
              " ((7, 6, 2, 5), (1, 1)),\n",
              " ((7, 5, 3, 5), (1, 1)),\n",
              " ((5, 5, 2, 8), (1, 1)),\n",
              " ((5, 4, 7, 14), (1, 1))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx0TsfGiQbN8",
        "outputId": "86933a76-6cbd-440a-8056-9ca73607c5b3"
      },
      "source": [
        "how_many = merge.filter(lambda x: x[1][0] != 0 and x[1][1] != 0)\n",
        "\n",
        "print(how_many.count())\n",
        "how_many.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((25, 14, 15, 16), (2, 1)),\n",
              " ((15, 8, 6, 11), (1, 1)),\n",
              " ((9, 4, 3, 2), (1, 1)),\n",
              " ((9, 3, 3, 5), (1, 1)),\n",
              " ((8, 9, 5, 6), (1, 1)),\n",
              " ((8, 5, 5, 14), (1, 2)),\n",
              " ((7, 6, 2, 5), (1, 1)),\n",
              " ((7, 5, 3, 5), (1, 1)),\n",
              " ((5, 5, 2, 8), (1, 1)),\n",
              " ((5, 4, 7, 14), (1, 1))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}